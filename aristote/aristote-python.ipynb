{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv('ARISTOTE_API_KEY')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dispatcher.aristote.centralesupelec.fr/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 14, 'total_tokens': 19, 'completion_tokens': 5}\n"
     ]
    }
   ],
   "source": [
    "stream=True\n",
    "request_body = {\n",
    "    'model': 'casperhansen/llama-3-70b-instruct-awq',\n",
    "    'messages': [\n",
    "        # {'role': 'user', 'content': 'who are you? reply with max 20 words'},\n",
    "        {'role': 'user', 'content': 'count to 2'},\n",
    "    ],\n",
    "    'stream': stream,\n",
    "    'stream_options': {\"include_usage\": True} if stream else None,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Bearer ' + api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# with requests.post(url, data=json.dumps(request_body), headers=headers, stream=stream) as response:\n",
    "#     if response.status_code == 200:\n",
    "#         # for chunk in response.iter_content(chunk_size=1024):\n",
    "#         for index, chunk in enumerate(response.iter_content(chunk_size=1024)):\n",
    "#             if chunk and chunk.startswith(b'data: '):\n",
    "#                 print(chunk.decode('utf-8'))\n",
    "#                 # print(chunk.decode('utf-8').count('data: '))\n",
    "\n",
    "#                 # match = re.search(r'\\{\"content\":\"[^\"]*\"\\}', chunk.decode('utf-8'))\n",
    "#                 # if match:\n",
    "#                 #     extracted_string = match.group(0)\n",
    "#                 #     print(extracted_string)\n",
    "\n",
    "#                 # match_done = re.search(r'\\[DONE\\]', chunk.decode('utf-8'))\n",
    "#                 # if match_done:\n",
    "#                 #     print('DONE')\n",
    "#                 #     break\n",
    "\n",
    "#                 # match_finish_reason = re.search('\"finish_reason\":\"stop\"', chunk.decode('utf-8'))\n",
    "#                 # if match_finish_reason:\n",
    "#                 #     extracted_string = match_finish_reason.group(0)\n",
    "#                 #     print(extracted_string)\n",
    "#                 #     print('stop')\n",
    "#                 #     # break\n",
    "\n",
    "#                 # match_usage = re.search(r'\\{\"prompt_tokens\":\\d+,\"total_tokens\":\\d+,\"completion_tokens\":\\d+\\}', chunk.decode('utf-8'))\n",
    "#                 # if match_usage:\n",
    "#                 #     extracted_string = match_usage.group(0)\n",
    "#                 #     json_usage = json.loads(extracted_string)\n",
    "#                 #     print(json_usage)\n",
    "#                 #     break\n",
    "#     else:\n",
    "#         print(f\"Failed to connect: {response.status_code}\")\n",
    "\n",
    "# USE DIFFERENTLY\n",
    "response = requests.post(url, data=json.dumps(request_body), headers=headers, stream=stream)\n",
    "if response.status_code == 200:\n",
    "    if not stream:\n",
    "        response = response.json()\n",
    "        print(response)\n",
    "    else:\n",
    "        # for chunk in response.iter_content(chunk_size=1024):\n",
    "        # for chunk in response.iter_content(chunk_size=None):\n",
    "        for index, chunk in enumerate(response.iter_content(chunk_size=None)):\n",
    "            if chunk and chunk.startswith(b'data: '):\n",
    "                # print(index)\n",
    "                # print(chunk.decode('utf-8'))\n",
    "                # print(chunk.decode('utf-8').count('data: '))\n",
    "\n",
    "                # match_content = re.search(r'\\{\"content\":\"[^\"]*\"\\}', chunk.decode('utf-8'))\n",
    "                # if match_content:\n",
    "                #     extracted_string = match_content.group(0)\n",
    "                #     print(extracted_string)\n",
    "                #     content = json.loads(extracted_string)['content']\n",
    "                #     print(content)\n",
    "\n",
    "                # match_done = re.search(r'\\[DONE\\]', chunk.decode('utf-8'))\n",
    "                # if match_done:\n",
    "                #     print('DONE')\n",
    "                #     break\n",
    "\n",
    "                # match_finish_reason = re.search('\"finish_reason\":\"stop\"', chunk.decode('utf-8'))\n",
    "                # if match_finish_reason:\n",
    "                #     extracted_string = match_finish_reason.group(0)\n",
    "                #     print(extracted_string)\n",
    "                #     # break\n",
    "\n",
    "                match_usage = re.search(r'\\{\"prompt_tokens\":\\d+,\"total_tokens\":\\d+,\"completion_tokens\":\\d+\\}', chunk.decode('utf-8'))\n",
    "                if match_usage:\n",
    "                    extracted_string = match_usage.group(0)\n",
    "                    json_usage = json.loads(extracted_string)\n",
    "                    print(json_usage)\n",
    "else:\n",
    "    print(f\"Failed to connect: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docAna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
