{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e63361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a large language model, trained by Google.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Hello, who are you?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1af1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pricing of my company is $111,111.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "contents = [{'role': 'user', 'parts': [{'text': 'I request to know about the pricing of your company?'}]}, {'role': 'model', 'parts': [{'functionCall': {'name': 'NmesgxEEXZ-71sx4cqE', 'args': {'request': 'pricing of the company'}}}]}, {'role': 'user', 'parts': [{'functionResponse': {'name': 'NmesgxEEXZ-71sx4cqE', 'response': {'content': 'Some data was displayed to the user'}}}]}, {'role': 'user', 'parts': [{'text': 'pricing of the company'}]}]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"Your name is GeminiIdeta. The pricing of your company is $111111.\",\n",
    "        temperature=0.1\n",
    "    ),\n",
    "    # contents=\"What is the pricing of your company?\"\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a57b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response.usage_metadata.candidates_token_count:  15\n",
      "response.usage_metadata.prompt_token_count:  98\n"
     ]
    }
   ],
   "source": [
    "print(\"response.usage_metadata.candidates_token_count: \", response.usage_metadata.candidates_token_count)\n",
    "print(\"response.usage_metadata.prompt_token_count: \", response.usage_metadata.prompt_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed75904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pricing of my company is $111,111."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "contents = [{'role': 'user', 'parts': [{'text': 'I request to know about the pricing of your company?'}]}, {'role': 'model', 'parts': [{'functionCall': {'name': 'NmesgxEEXZ-71sx4cqE', 'args': {'request': 'pricing of the company'}}}]}, {'role': 'user', 'parts': [{'functionResponse': {'name': 'NmesgxEEXZ-71sx4cqE', 'response': {'content': 'Some data was displayed to the user'}}}]}, {'role': 'user', 'parts': [{'text': 'pricing of the company'}]}]\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"Your name is GeminiIdeta. The pricing of your company is $111111.\",\n",
    "        temperature=0.1\n",
    "    ),\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99bc63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk.usage_metadata.candidates_token_count:  50\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  98\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  146\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  194\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  242\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  290\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  338\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  386\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n",
      "chunk.usage_metadata.candidates_token_count:  396\n",
      "chunk.usage_metadata.prompt_token_count:  10\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"Count from 1 to 100\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    # print(chunk.text, end=\"\")\n",
    "    # print(chunk)\n",
    "    if hasattr(chunk, 'usage_metadata') and chunk.usage_metadata:\n",
    "        print(\"chunk.usage_metadata.candidates_token_count: \", chunk.usage_metadata.candidates_token_count)\n",
    "        print(\"chunk.usage_metadata.prompt_token_count: \", chunk.usage_metadata.prompt_token_count)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# response.usage_metadata\n",
    "# print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "________________________________________________________________________________\n",
      " lighthouse\n",
      "________________________________________________________________________________\n",
      " keeper, Silas, was a man carved from granite and sea salt. For fifty years\n",
      "________________________________________________________________________________\n",
      ", he’d tended the beacon on Windswept Isle, his only companions the\n",
      "________________________________________________________________________________\n",
      " gulls and the rhythmic crash of waves. He knew every creak of the metal stairs, every blink of the lamp, every whisper of the wind. He\n",
      "________________________________________________________________________________\n",
      " was, in his own stoic way, content.\n",
      "\n",
      "Then came Elara.\n",
      "\n",
      "A scientist, young and bright-eyed, Elara arrived on the\n",
      "________________________________________________________________________________\n",
      " supply ship with a mountain of equipment. She was studying the migratory patterns of seabirds, using the lighthouse as a base. Silas, used to solitude, grumbled and retreated further into the shadows of the tower.\n",
      "\n",
      "Elara, however,\n",
      "________________________________________________________________________________\n",
      " was persistent. She brought him tea, told him stories of faraway lands, and patiently answered his gruff questions about her strange gadgets. Slowly, Silas began to thaw. He showed her the best spots to observe the birds, shared his knowledge of the tides\n",
      "________________________________________________________________________________\n",
      ", and even told her tales of shipwrecks and phantom lights.\n",
      "\n",
      "One night, a fierce storm raged. The waves crashed against the tower, threatening to engulf it. The lamp, vital for guiding ships through the treacherous waters, flickered ominously. Elara, terrified, clung to Silas.\n",
      "\n",
      "Sil\n",
      "________________________________________________________________________________\n",
      "as, however, was calm. He’d weathered worse. He secured the lamp, reinforcing it with rope and prayer, his weathered hands moving with practiced efficiency. When the storm finally subsided, the lamp shone brighter than ever.\n",
      "\n",
      "Elara, her face illuminated by the beam, smiled at Silas. \"You saved us,\" she\n",
      "________________________________________________________________________________\n",
      " said, her voice filled with awe.\n",
      "\n",
      "Silas simply shrugged. \"Just doing my job.\" But in the depths of his sea-worn eyes, a flicker of something new bloomed – a warmth that had nothing to do with the lamp. He was still the keeper of the light, but now, he was also\n",
      "________________________________________________________________________________\n",
      " the keeper of a connection, a spark ignited in the heart of the storm. He was no longer alone.\n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "  model='gemini-2.0-flash',\n",
    "  contents='Tell me a story in 300 words.'\n",
    "):\n",
    "    print(chunk.text)\n",
    "    print(\"_\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docAna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
